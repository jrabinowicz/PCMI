{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leer_instancia(path_instancia):\n",
    "    with open(path_instancia, \"r\") as f:\n",
    "        return f.read();\n",
    "\n",
    "def correr_experimento(metodo, archivo_instancia):\n",
    "    # Leer archivo de la instancia.\n",
    "    instancia = leer_instancia(archivo_instancia)\n",
    "    \n",
    "    # Crear proceso para ejecutar el codigo.\n",
    "    process = subprocess.Popen([\"../exe\", metodo], stderr=subprocess.PIPE, stdout=subprocess.PIPE, stdin=subprocess.PIPE, universal_newlines = True)\n",
    "\n",
    "    # Poner la instancia en la entrada estandar y leer salida de STDERR con el tiempo de ejecuci√≥n.\n",
    "    #tiempo_de_ejecucion = process.communicate(instancia)[1] # communicate() devuelve una tupla (stdout, stderr)\n",
    "    #impacto_conseguido = process.communicate(instancia)[0]\n",
    "\n",
    "    tupla = process.communicate(instancia)\n",
    "\n",
    "    # Correr experimento.\n",
    "    exit_code = process.wait()\n",
    "\n",
    "    # Verificar que el proceso no fallo.\n",
    "    if exit_code != 0: raise(F\"Hubo un error en la experimentacion para el algoritmo: {algoritmo} con la instancia {archivo_instancia}.\")\n",
    "    \n",
    "    return tupla;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instancias generales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h1 = pd.read_csv(\"instancias/indice-h1.csv\");\n",
    "df_h2 = pd.read_csv(\"instancias/indice-h2.csv\");\n",
    "df_TB_H1_MSE_MBI = pd.read_csv(\"instancias/indice-TB-H1-MSE-MBI.csv\");\n",
    "df_TB_H1_ME_MBI = pd.read_csv(\"instancias/indice-TB-H1-ME-MBI.csv\");\n",
    "df_TB_H2_MSE_MBI = pd.read_csv(\"instancias/indice-TB-H2-MSE-MBI.csv\");\n",
    "df_TB_H2_ME_MBI = pd.read_csv(\"instancias/indice-TB-H2-ME-MBI.csv\");\n",
    "df_TB_H1_MSE_BI = pd.read_csv(\"instancias/indice-TB-H1-MSE-BI.csv\");\n",
    "df_TB_H1_ME_BI = pd.read_csv(\"instancias/indice-TB-H1-ME-BI.csv\");\n",
    "df_TB_H2_MSE_BI = pd.read_csv(\"instancias/indice-TB-H2-MSE-BI.csv\");\n",
    "df_TB_H2_ME_BI = pd.read_csv(\"instancias/indice-TB-H2-ME-BI.csv\");\n",
    "df_TB_H1_MSE_MI = pd.read_csv(\"instancias/indice-TB-H1-MSE-MI.csv\");\n",
    "df_TB_H1_ME_MI = pd.read_csv(\"instancias/indice-TB-H1-ME-MI.csv\");\n",
    "df_TB_H2_MSE_MI = pd.read_csv(\"instancias/indice-TB-H2-MSE-MI.csv\");\n",
    "df_TB_H2_ME_MI = pd.read_csv(\"instancias/indice-TB-H2-ME-MI.csv\");\n",
    "df_TB_H1_MSE_AI = pd.read_csv(\"instancias/indice-TB-H1-MSE-AI.csv\");\n",
    "df_TB_H1_ME_AI = pd.read_csv(\"instancias/indice-TB-H1-ME-AI.csv\");\n",
    "df_TB_H2_MSE_AI = pd.read_csv(\"instancias/indice-TB-H2-MSE-AI.csv\");\n",
    "df_TB_H2_ME_AI = pd.read_csv(\"instancias/indice-TB-H2-ME-AI.csv\");\n",
    " \n",
    "experimentos = [];"
   ]
  },
  {
   "source": [
    "## Heuristicas"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Heuristica 1 (h1)\n",
    " \n",
    " for n in range(len(df_h1)):\n",
    "    fila_n = df_h1.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"n\"], fila_n[\"Impacto\"], \"H1\", fila_n[\"archivo\"]]);\n",
    "\n",
    " # Heuristica 2 (h2)\n",
    " \n",
    " for n in range(len(df_h2)):\n",
    "    fila_n = df_h2.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"n\"], fila_n[\"Impacto\"], \"H2\", fila_n[\"archivo\"]]);"
   ]
  },
  {
   "source": [
    "## Bajas iteraciones"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Tabu Search inicializada con la H1 usando memoria SE con muy bajas (50) iteraciones (TB_H1_MSE_MBI)\n",
    " \n",
    " for n in range(len(df_TB_H1_MSE_MBI)):\n",
    "    fila_n = df_TB_H1_MSE_MBI.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"n\"], fila_n[\"Impacto\"], \"TB-H1-MSE-MBI\", fila_n[\"archivo\"]]);\n",
    "\n",
    "# Tabu Search inicializada con la H1 usando memoria por estrc. con muy bajas (50) iteraciones (TB_H1_ME_MBI)\n",
    " \n",
    "for n in range(len(df_TB_H1_ME_MBI)):\n",
    "    fila_n = df_TB_H1_ME_MBI.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"n\"], fila_n[\"Impacto\"], \"TB-H1-ME-MBI\", fila_n[\"archivo\"]]);\n",
    "\n",
    "# Tabu Search inicializada con la H2 usando memoria SE con muy bajas (50) iteraciones (TB_H2_MSE_MBI)\n",
    " \n",
    "for n in range(len(df_TB_H2_MSE_MBI)):\n",
    "    fila_n = df_TB_H2_MSE_MBI.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"n\"], fila_n[\"Impacto\"], \"TB-H2-MSE-MBI\", fila_n[\"archivo\"]]);\n",
    "\n",
    "# Tabu Search inicializada con la H2 usando memoria por estrc. con muy bajas (50) iteraciones (TB_H2_ME_MBI)\n",
    " \n",
    "for n in range(len(df_TB_H2_ME_MBI)):\n",
    "    fila_n = df_TB_H2_ME_MBI.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"n\"], fila_n[\"Impacto\"], \"TB-H2-ME-MBI\", fila_n[\"archivo\"]]);"
   ]
  },
  {
   "source": [
    "## Bajas iteraciones"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Tabu Search inicializada con la H1 usando memoria SE con bajas (500) iteraciones (TB_H1_MSE_BI)\n",
    " \n",
    " for n in range(len(df_TB_H1_MSE_BI)):\n",
    "    fila_n = df_TB_H1_MSE_BI.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"n\"], fila_n[\"Impacto\"], \"TB-H1-MSE-BI\", fila_n[\"archivo\"]]);\n",
    "\n",
    " # Tabu Search inicializada con la H1 usando memoria por estrc. con bajas (500) iteraciones (TB_H1_ME_BI)\n",
    " \n",
    " for n in range(len(df_TB_H1_ME_BI)):\n",
    "    fila_n = df_TB_H1_ME_BI.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"n\"], fila_n[\"Impacto\"], \"TB-H1-ME-BI\", fila_n[\"archivo\"]]);\n",
    "\n",
    " # Tabu Search inicializada con la H2 usando memoria SE con bajas (500) iteraciones (TB_H2_MSE_BI)\n",
    " \n",
    " for n in range(len(df_TB_H2_MSE_BI)):\n",
    "    fila_n = df_TB_H2_MSE_BI.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"n\"], fila_n[\"Impacto\"], \"TB-H2-MSE-BI\", fila_n[\"archivo\"]]);\n",
    "\n",
    " # Tabu Search inicializada con la H2 usando memoria por estrc. con bajas (500) iteraciones (TB_H2_ME_BI)\n",
    " \n",
    " for n in range(len(df_TB_H2_ME_BI)):\n",
    "    fila_n = df_TB_H2_ME_BI.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"n\"], fila_n[\"Impacto\"], \"TB-H2-ME-BI\", fila_n[\"archivo\"]]);"
   ]
  },
  {
   "source": [
    "## Medias iteraciones"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Tabu Search inicializada con la H1 usando memoria SE con medias (1000) iteraciones (TB_H2_MSE_MI)\n",
    " \n",
    " for n in range(len(df_TB_H1_MSE_MI)):\n",
    "    fila_n = df_TB_H1_MSE_MI.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"n\"], fila_n[\"Impacto\"], \"TB-H1-MSE-MI\", fila_n[\"archivo\"]]);\n",
    "\n",
    "# Tabu Search inicializada con la H1 usando memoria por estrc. con medias (1000) iteraciones (TB_H1_ME_MI)\n",
    " \n",
    "for n in range(len(df_TB_H1_ME_MI)):\n",
    "    fila_n = df_TB_H1_ME_MI.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"n\"], fila_n[\"Impacto\"], \"TB-H1-ME-MI\", fila_n   [\"archivo\"]]);\n",
    "\n",
    "# Tabu Search inicializada con la H1 usando memoria SE con medias (1000) iteraciones (TB_H2_MSE_MI)\n",
    " \n",
    "for n in range(len(df_TB_H2_MSE_MI)):\n",
    "    fila_n = df_TB_H2_MSE_MI.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"n\"], fila_n[\"Impacto\"], \"TB-H2-MSE-MI\", fila_n[\"archivo\"]]);\n",
    "\n",
    "# Tabu Search inicializada con la H1 usando memoria por estrc. con medias (1000) iteraciones (TB_H2_ME_MI)\n",
    " \n",
    "for n in range(len(df_TB_H2_ME_MI)):\n",
    "    fila_n = df_TB_H2_ME_MI.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"n\"], fila_n[\"Impacto\"], \"TB-H2-ME-MI\", fila_n[\"archivo\"]]);"
   ]
  },
  {
   "source": [
    "## Altas iteraciones"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabu Search inicializada con la H1 usando memoria por estrc. con medias (1000) iteraciones (TB_H1_MSE_AI)\n",
    " \n",
    "for n in range(len(df_TB_H1_MSE_AI)):\n",
    "    fila_n = df_TB_H1_MSE_AI.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"n\"], fila_n[\"Impacto\"], \"TB-H1-MSE-AI\", fila_n[\"archivo\"]]);\n",
    "\n",
    "# Tabu Search inicializada con la H1 usando memoria por estrc. con medias (1000) iteraciones (TB_H1_ME_AI)\n",
    " \n",
    "for n in range(len(df_TB_H1_ME_AI)):\n",
    "    fila_n = df_TB_H1_ME_AI.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"n\"], fila_n[\"Impacto\"], \"TB-H1-ME-AI\", fila_n[\"archivo\"]]);\n",
    "\n",
    "# Tabu Search inicializada con la H1 usando memoria por estrc. con medias (1000) iteraciones (TB_H2_MSE_AI)\n",
    " \n",
    "for n in range(len(df_TB_H2_MSE_AI)):\n",
    "    fila_n = df_TB_H2_MSE_AI.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"n\"], fila_n[\"Impacto\"], \"TB-H2-MSE-AI\", fila_n[\"archivo\"]]);\n",
    "\n",
    "# Tabu Search inicializada con la H1 usando memoria por estrc. con medias (1000) iteraciones (TB_H2_ME_AI)\n",
    " \n",
    "for n in range(len(df_TB_H2_ME_AI)):\n",
    "    fila_n = df_TB_H2_ME_AI.iloc[n];\n",
    "    experimentos.append([fila_n[\"dataset\"], fila_n[\"n\"], fila_n[\"Impacto\"], \"TB-H2-ME-AI\", fila_n[\"archivo\"]]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "len(experimentos)"
   ]
  },
  {
   "source": [
    "## Ejecutar los experimentos de las instancias generales y guardar los resultados en un archivo CSV."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "'Experimento: 234/234'"
     },
     "metadata": {}
    }
   ],
   "source": [
    "columnas = [\"dataset\", \"n\", \"Impacto Optimo\", \"Impacto Conseguido\", \"tiempo\"];\n",
    "filas = [];\n",
    "numero = 1\n",
    "T = 5 # Numero de veces que se ejecuta cada experimento (para mayor fidelidad del tiempo).\n",
    "for experimento in experimentos:\n",
    "    # Voy mostrando que experimento se esta ejecutando.\n",
    "    clear_output(wait=True)\n",
    "    display(\"Experimento: \" + str(numero) + \"/\" + str(len(experimentos)))\n",
    "    numero += 1\n",
    "    \n",
    "    # Ejecutamos el experimento T veces y obtenemos la mediana.\n",
    "    tiempos = []\n",
    "    impactos_conseguidos = []\n",
    "    for i in range(0, T):\n",
    "        tupla = correr_experimento(experimento[3], experimento[4]);\n",
    "        tiempos.append(float(tupla[1]));\n",
    "        impactos_conseguidos.append(float(tupla[0][0:2]));\n",
    "    tiempo = np.median(tiempos);\n",
    "    impacto_conseguido = np.median(impactos_conseguidos);\n",
    "    filas.append([experimento[0], experimento[1], experimento[2], impacto_conseguido, tiempo]);\n",
    "df_resultado = pd.DataFrame(filas, columns=columnas);\n",
    "df_resultado.to_csv(\"resultados/resultado.csv\", index=False, header=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instancias de Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TB_H1_MSE_MIN = pd.read_csv(\"instanciasTest/indice-TB-H1-MSE-MIN.csv\");\n",
    "df_TB_H1_ME_MIN = pd.read_csv(\"instanciasTest/indice-TB-H1-ME-MIN.csv\");\n",
    "df_TB_H2_MSE_MIN = pd.read_csv(\"instanciasTest/indice-TB-H2-MSE-MIN.csv\");\n",
    "df_TB_H2_ME_MIN = pd.read_csv(\"instanciasTest/indice-TB-H2-ME-MIN.csv\");\n",
    "\n",
    "df_TB_H1_MSE_MBIN = pd.read_csv(\"instanciasTest/indice-TB-H1-MSE-MBIN.csv\");\n",
    "df_TB_H1_ME_MBIN = pd.read_csv(\"instanciasTest/indice-TB-H1-ME-MBIN.csv\");\n",
    "df_TB_H2_MSE_MBIN = pd.read_csv(\"instanciasTest/indice-TB-H2-MSE-MBIN.csv\");\n",
    "df_TB_H2_ME_MBIN = pd.read_csv(\"instanciasTest/indice-TB-H2-ME-MBIN.csv\");\n",
    "\n",
    "experimentos_nuevos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Tabu Search inicializada con la H1 usando memoria SE con medias (1000) iteraciones (TB_H1_MSE_MI)\n",
    " \n",
    " for n in range(len(df_TB_H1_MSE_MIN)):\n",
    "    fila_n = df_TB_H1_MSE_MIN.iloc[n];\n",
    "    experimentos_nuevos.append([fila_n[\"dataset\"], fila_n[\"n\"], fila_n[\"Impacto\"], \"TB-H1-MSE-MI\", fila_n[\"archivo\"]]);\n",
    "\n",
    " # Tabu Search inicializada con la H1 usando memoria por estruc. con medias (1000) iteraciones (TB_H1_MSE_MI)\n",
    " \n",
    " for n in range(len(df_TB_H1_ME_MIN)):\n",
    "    fila_n = df_TB_H1_ME_MIN.iloc[n];\n",
    "    experimentos_nuevos.append([fila_n[\"dataset\"], fila_n[\"n\"], fila_n[\"Impacto\"], \"TB-H1-ME-MI\", fila_n[\"archivo\"]]);\n",
    "\n",
    " # Tabu Search inicializada con la H2 usando memoria por estruc. con medias (1000) iteraciones (TB_H2_MSE_MI)\n",
    " \n",
    " for n in range(len(df_TB_H2_MSE_MIN)):\n",
    "    fila_n = df_TB_H2_MSE_MIN.iloc[n];\n",
    "    experimentos_nuevos.append([fila_n[\"dataset\"], fila_n[\"n\"], fila_n[\"Impacto\"], \"TB-H2-MSE-MI\", fila_n[\"archivo\"]]);\n",
    "\n",
    " # Tabu Search inicializada con la H2 usando memoria por estruc. con medias (1000) iteraciones (TB_H2_ME_MI)\n",
    " \n",
    " for n in range(len(df_TB_H2_ME_MIN)):\n",
    "    fila_n = df_TB_H2_ME_MIN.iloc[n];\n",
    "    experimentos_nuevos.append([fila_n[\"dataset\"], fila_n[\"n\"], fila_n[\"Impacto\"], \"TB-H2-ME-MI\", fila_n[\"archivo\"]]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Tabu Search inicializada con la H1 usando memoria SE con altas (2500) iteraciones (TB_H1_MSE_MBI)\n",
    " \n",
    " for n in range(len(df_TB_H1_MSE_MBIN)):\n",
    "    fila_n = df_TB_H1_MSE_MBIN.iloc[n];\n",
    "    experimentos_nuevos.append([fila_n[\"dataset\"], fila_n[\"n\"], fila_n[\"Impacto\"], \"TB-H1-MSE-MBI\", fila_n[\"archivo\"]]);\n",
    "\n",
    " # Tabu Search inicializada con la H1 usando memoria por estruc. con altas (2500) iteraciones (TB_H1_MSE_MBI)\n",
    " \n",
    " for n in range(len(df_TB_H1_ME_MBIN)):\n",
    "    fila_n = df_TB_H1_ME_MBIN.iloc[n];\n",
    "    experimentos_nuevos.append([fila_n[\"dataset\"], fila_n[\"n\"], fila_n[\"Impacto\"], \"TB-H1-ME-MBI\", fila_n[\"archivo\"]]);\n",
    "\n",
    " # Tabu Search inicializada con la H2 usando memoria por estruc. con altas (2500) iteraciones (TB_H2_MSE_MBI)\n",
    " \n",
    " for n in range(len(df_TB_H2_MSE_MBIN)):\n",
    "    fila_n = df_TB_H2_MSE_MBIN.iloc[n];\n",
    "    experimentos_nuevos.append([fila_n[\"dataset\"], fila_n[\"n\"], fila_n[\"Impacto\"], \"TB-H2-MSE-MBI\", fila_n[\"archivo\"]]);\n",
    "\n",
    " # Tabu Search inicializada con la H2 usando memoria por estruc. con altas (2500) iteraciones (TB_H2_ME_MBI)\n",
    " \n",
    " for n in range(len(df_TB_H2_ME_MBIN)):\n",
    "    fila_n = df_TB_H2_ME_MBIN.iloc[n];\n",
    "    experimentos_nuevos.append([fila_n[\"dataset\"], fila_n[\"n\"], fila_n[\"Impacto\"], \"TB-H2-ME-MBI\", fila_n[\"archivo\"]]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "print(len(experimentos_nuevos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejecutar los experimentos de las instancias de test y guardar los resultados en un archivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "'Experimento: 96/96'"
     },
     "metadata": {}
    }
   ],
   "source": [
    "columnas_test = [\"dataset\", \"n\", \"Impacto Optimo\", \"Impacto Conseguido\", \"tiempo\"];\n",
    "filas_test = [];\n",
    "numero = 1\n",
    "T = 5 # Numero de veces que se ejecuta cada experimento (para mayor fidelidad del tiempo).\n",
    "for experimento in experimentos_nuevos:\n",
    "    # Voy mostrando que experimento se esta ejecutando.\n",
    "    clear_output(wait=True)\n",
    "    display(\"Experimento: \" + str(numero) + \"/\" + str(len(experimentos_nuevos)))\n",
    "    numero += 1\n",
    "    \n",
    "    # Ejecutamos el experimento T veces y obtenemos la mediana.\n",
    "    tiempos = []\n",
    "    impactos_conseguidos = []\n",
    "    for i in range(0, T):\n",
    "        tupla = correr_experimento(experimento[3], experimento[4]);\n",
    "        tiempos.append(float(tupla[1]));\n",
    "        impactos_conseguidos.append(float(tupla[0][0:2]));\n",
    "    tiempo = np.median(tiempos);\n",
    "    impacto_conseguido = np.median(impactos_conseguidos);\n",
    "    filas_test.append([experimento[0], experimento[1], experimento[2], impacto_conseguido, tiempo]);\n",
    "df_resultado = pd.DataFrame(filas_test, columns=columnas_test);\n",
    "df_resultado.to_csv(\"resultados/resultadoTest.csv\", index=False, header=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}